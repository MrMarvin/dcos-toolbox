# my global config
global:
  scrape_interval: 15s      # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  scrape_timeout: 10s       # scrape_timeout is set to the global default (10s).
  evaluation_interval: 15s  # Evaluate rules every 15 seconds. The default is every 1 minute.

# Alertmanager configuration
alerting:
  alertmanagers:
  - static_configs:
    - targets:
    # - alertmanager:9093
    scheme: http
    timeout: 10s

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
# The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
- job_name: prometheus
# metrics_path defaults to '/metrics'
# scheme defaults to 'http'.
  scrape_interval: 15s
  scrape_timeout: 10s
  metrics_path: /service/dcos/prometheus/prometheus/metrics
  scheme: http
  static_configs:
  - targets:
    - dcosprometheusprometheus.marathon.l4lb.thisdcos.directory:9090

# Collect metrics from prometheus/statsd_exporter for Docker Containers
- job_name: prometheus-statsd-exporter
  scrape_interval: 15s
  scrape_timeout: 10s
  metrics_path: /metrics
  scheme: http
  static_configs:
  - targets:
    - dcosprometheusstatsd-exporter.marathon.l4lb.thisdcos.directory:9102

# Collect metrics from DC/OS Masters
- job_name: dcos-masters
  scrape_interval: 15s
  scrape_timeout: 10s
  metrics_path: /metrics
  scheme: http
  static_configs:
  - targets:
    - 10.0.4.129:61091

# Collect metrics from DC/OS Agents
- job_name: dcos-agents
  scrape_interval: 15s
  scrape_timeout: 10s
  metrics_path: /metrics
  scheme: http
  static_configs:
  - targets:
    - 10.0.0.130:61091
    - 10.0.0.166:61091
    - 10.0.2.161:61091
    - 10.0.6.238:61091
    - 10.0.0.164:61091
    - 10.0.3.146:61091
    - 10.0.3.90:61091
    - 10.0.2.194:61091
    - 10.0.1.194:61091
    - 10.0.3.183:61091
